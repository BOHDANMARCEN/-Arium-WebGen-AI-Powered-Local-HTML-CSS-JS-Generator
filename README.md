# ğŸŒ Arium WebGen â€” AI-Powered Local HTML/CSS/JS Generator

<div align="center">

**Lightweight. Fast. Local-first. Perfect companion to Arium IDE.**

[![Next.js](https://img.shields.io/badge/Next.js-15-black)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19-blue)](https://react.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue)](https://www.typescriptlang.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

[Demo](#) â€¢ [Documentation](#-documentation) â€¢ [Issues](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator/issues) â€¢ [Discussions](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator/discussions)

</div>

---

## ğŸ“– About the Project

**Arium WebGen** is a modern local AI-powered web page generator that creates complete HTML, CSS, and JavaScript pages based on simple text descriptions. The project works entirely locally (Ollama / LM Studio) or through any OpenAI-compatible API.

This is a minimal, fast tool for developers, designers, and AI enthusiasts â€” and a key component of the **Arium** ecosystem.

### ğŸ“¸ Screenshots

<div align="center">

![Welcome Screen](./screenshots/1.png)
*Welcome screen with provider selection*

![Code Generation](./screenshots/2.png)
*Real-time code generation with live preview*

![Generated Result](./screenshots/3.png)
*Generated web page with code editor*

</div>

### âœ¨ Key Features

- ğŸ¤– **AI Web Page Generation** â€” Create complete web pages from natural descriptions
- ğŸ‘ï¸ **Live Preview** â€” View results in real-time on different devices (Desktop, Mobile, Tablet)
- âœï¸ **Built-in Code Editor** â€” Monaco Editor for on-the-fly code editing
- ğŸ”Œ **Multiple AI Provider Support** â€” Ollama, LM Studio, DeepSeek, OpenAI-compatible APIs
- ğŸ§  **Thinking Models** â€” Support for reasoning models (Qwen, DeepCoder, etc.)
- ğŸ¨ **Modern UI** â€” Dark interface built on Next.js 15, React 19, Tailwind CSS, and shadcn/ui
- ğŸ³ **Docker Support** â€” Easy deployment via Docker container

---

## ğŸš€ Quick Start

### Requirements

- Node.js 20+ or Docker
- npm, yarn, or pnpm
- (Optional) Ollama or LM Studio for local models

### Installation

1. **Clone the repository:**

```bash
git clone https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator.git
cd -Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator
```

2. **Install dependencies:**

```bash
npm install
# or
yarn install
# or
pnpm install
```

3. **Configure environment variables:**

Create a `.env.local` file in the project root:

```env
# DeepSeek Configuration
DEEPSEEK_API_KEY=your_deepseek_api_key
DEEPSEEK_API_BASE=https://api.deepseek.com/v1

# Local Providers (Ollama)
OLLAMA_API_BASE=http://localhost:11434

# Local Providers (LM Studio)
LM_STUDIO_API_BASE=http://localhost:1234/v1

# Custom OpenAI-compatible API
# OPENAI_COMPATIBLE_API_KEY=your_key_here
# OPENAI_COMPATIBLE_API_BASE=https://api.provider.com/v1

# Default Provider (ollama, lm_studio, deepseek, openai_compatible)
DEFAULT_PROVIDER=lm_studio
```

4. **Run the project:**

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
```

5. **Open your browser:**

Navigate to [http://localhost:3000](http://localhost:3000)

---

## ğŸ³ Docker

### Running with Docker

```bash
docker build -t arium-webgen .
docker run -p 3000:3000 \
  -e DEFAULT_PROVIDER=lm_studio \
  -e OLLAMA_API_BASE=http://host.docker.internal:11434 \
  -e LM_STUDIO_API_BASE=http://host.docker.internal:1234/v1 \
  arium-webgen
```

### Docker Compose

```yaml
version: '3.8'
services:
  webgen:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DEFAULT_PROVIDER=lm_studio
      - OLLAMA_API_BASE=http://host.docker.internal:11434
      - LM_STUDIO_API_BASE=http://host.docker.internal:1234/v1
```

---

## ğŸ§  Supported Providers

### ğŸ”¸ Local Models

#### Ollama
- **Description:** Local AI models via Ollama
- **Setup:** Install [Ollama](https://ollama.ai/) and start the server
- **API Base:** `http://localhost:11434`
- **API Key:** Not required

#### LM Studio
- **Description:** Local AI models via LM Studio
- **Setup:** Install [LM Studio](https://lmstudio.ai/) and start the local server
- **API Base:** `http://localhost:1234/v1`
- **API Key:** Not required

### ğŸ”¸ Cloud Providers

#### DeepSeek
- **Description:** AI models from DeepSeek
- **Setup:** Get an API key from [DeepSeek](https://www.deepseek.com/)
- **API Base:** `https://api.deepseek.com/v1`
- **API Key:** Required

#### Custom OpenAI-compatible API
- **Description:** Any OpenAI-compatible API
- **Supported Services:** OpenAI, Together AI, Anyscale, Groq, Claude AI, Anthropic, and more
- **Setup:** Specify the base URL and API key in `.env.local`

---

## ğŸ›  How to Use

### Basic Usage

1. **Enter a web page description**
   - Example: "Create a landing page for a mobile app in purple tones with animations"

2. **Select AI provider and model**
   - Choose a provider (Ollama, LM Studio, DeepSeek, etc.)
   - Select a model from available options

3. **Configure parameters (optional)**
   - System prompt (default, thinking, custom)
   - Maximum token count

4. **Click GENERATE**
   - AI will start generating code in real-time
   - For thinking models, you'll see the reasoning process

5. **View and edit**
   - View results in Live Preview
   - Edit code in the built-in editor
   - Switch between Desktop, Mobile, and Tablet modes

6. **Export the result**
   - Copy code or save locally

### Advanced Features

- **Thinking Models:** Use reasoning models for better understanding of the generation process
- **Custom System Prompts:** Create custom system prompts for specific tasks
- **Token Limits:** Configure maximum token count to control response length

---

## ğŸ“ Project Structure

```
Arium-WebGen/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ generate-code/ # Code generation
â”‚   â”‚   â”œâ”€â”€ get-models/    # Get models
â”‚   â”‚   â””â”€â”€ get-default-provider/
â”‚   â”œâ”€â”€ layout.tsx         # Root layout
â”‚   â””â”€â”€ page.tsx           # Main page
â”œâ”€â”€ components/            # React components
â”‚   â”œâ”€â”€ ui/               # shadcn/ui components
â”‚   â”œâ”€â”€ code-editor.tsx   # Monaco Editor
â”‚   â”œâ”€â”€ generation-view.tsx
â”‚   â”œâ”€â”€ welcome-view.tsx
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lib/                  # Utilities and configuration
â”‚   â”œâ”€â”€ providers/        # Provider configuration
â”‚   â””â”€â”€ utils.ts
â”œâ”€â”€ public/               # Static files
â”œâ”€â”€ Dockerfile           # Docker configuration
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## ğŸ—º Roadmap

### ğŸ§© Models and Providers

- [x] Ollama support
- [x] LM Studio support
- [x] DeepSeek
- [x] OpenAI-compatible API
- [x] Thinking Models Support (Qwen, DeepCoder, etc.)
- [ ] Anthropic Claude
- [ ] Groq
- [ ] Together AI
- [ ] Perplexity

### ğŸ§± Code Generation

- [ ] Multi-file structure (index.html, style.css, app.js)
- [ ] ZIP project export
- [ ] Agentic diff-editing
- [ ] Projects: save / history
- [ ] Versioning of generated code

### ğŸ¨ Interface

- [ ] Light theme
- [ ] Custom editor settings
- [ ] Drag-and-drop UI components
- [ ] Templates and examples
- [ ] Generation history

### ğŸ’» Desktop Version

- [ ] Electron app
- [ ] Native notifications
- [ ] Offline mode

### ğŸ”§ Developer Tools

- [ ] CLI version
- [ ] VS Code extension
- [ ] API for integrations

---

## ğŸ¤ Contributing

We welcome contributions! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

### How to Contribute

1. Fork the project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“š Documentation

- [Architecture 3.0](docs/ARCHITECTURE.md) - Comprehensive architecture document with diagrams and implementation plan
- [Architecture 3.0 Starter Code](docs/ARCHITECTURE_3_STARTER.md) - Full project description with ready-to-use starter code
- [Provider Setup](docs/PROVIDERS.md)
- [API Documentation](docs/API.md)
- [Development](docs/DEVELOPMENT.md)

---

## ğŸ› Issues and Support

If you found a bug or have a suggestion, please:
- Check [existing issues](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator/issues)
- Create a [new issue](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator/issues/new) with a detailed description

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Next.js](https://nextjs.org/) for the amazing framework
- [shadcn/ui](https://ui.shadcn.com/) for UI components
- [Monaco Editor](https://microsoft.github.io/monaco-editor/) for the code editor
- All contributors and users of the project

---

<div align="center">

**Made with â¤ï¸ for the developer community**

[â­ Star the project](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator) â€¢ [ğŸ› Report a bug](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/BOHDANMARCEN/-Arium-WebGen-AI-Powered-Local-HTML-CSS-JS-Generator/discussions)

</div>
